#!/usr/bin/env node

/**
 * Research Source Collection Script - Phase 2 Implementation
 * 
 * This script performs automated research source collection, classification, and scoring.
 * It fetches real data from the web, analyzes content, and populates RESEARCH_SOURCES.md
 * with comprehensive references across all 8 research dimensions.
 * 
 * Phase 2: Live scraping, content extraction, and source population (‚â•25 sources)
 */

'use strict';

const fs = require('fs');
const path = require('path');
const https = require('https');
const http = require('http');
const cheerio = require('cheerio');

// Curated list of high-quality sources to collect across all research dimensions
const SOURCES_TO_COLLECT = [
  // Existing Platforms & Benchmarks
  { url: 'https://github.com/dicedotfun/contracts', dimension: 'Existing Platforms & Benchmarks', title: 'Dice.fun - Provably Fair Dice Contracts' },
  { url: 'https://github.com/Roll20/roll20-character-sheets', dimension: 'Existing Platforms & Benchmarks', title: 'Roll20 Character Sheets Repository' },
  { url: 'https://docs.primedice.com/provably-fair', dimension: 'Existing Platforms & Benchmarks', title: 'PrimeDice Provably Fair Documentation' },
  
  // Randomness & Fairness
  { url: 'https://github.com/smartcontractkit/chainlink', dimension: 'Randomness & Fairness', title: 'Chainlink - Decentralized Oracle Network' },
  { url: 'https://github.com/drand/drand', dimension: 'Randomness & Fairness', title: 'drand - Distributed Randomness Beacon' },
  { url: 'https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-90Ar1.pdf', dimension: 'Randomness & Fairness', title: 'NIST SP 800-90A - Random Number Generation' },
  { url: 'https://github.com/ethereum/EIPs/blob/master/EIPS/eip-4399.md', dimension: 'Randomness & Fairness', title: 'EIP-4399: Supplant DIFFICULTY opcode with PREVRANDAO' },
  
  // Anti-Cheat & Verification  
  { url: 'https://github.com/opencv/opencv', dimension: 'Anti-Cheat & Verification', title: 'OpenCV - Computer Vision Library' },
  { url: 'https://github.com/tensorflow/models/tree/master/research/object_detection', dimension: 'Anti-Cheat & Verification', title: 'TensorFlow Object Detection' },
  { url: 'https://github.com/deepfakes/faceswap', dimension: 'Anti-Cheat & Verification', title: 'Deepfake Detection Research' },
  { url: 'https://github.com/serengil/deepface', dimension: 'Anti-Cheat & Verification', title: 'DeepFace - Facial Recognition Framework' },
  
  // Reputation & Trust Models
  { url: 'https://github.com/Glicko2/glicko2', dimension: 'Reputation & Trust Models', title: 'Glicko-2 Rating System Implementation' },
  { url: 'https://github.com/sublee/elo', dimension: 'Reputation & Trust Models', title: 'ELO Rating System Library' },
  { url: 'https://stackoverflow.blog/2009/01/06/stack-overflow-reputation-system/', dimension: 'Reputation & Trust Models', title: 'Stack Overflow Reputation System Design' },
  { url: 'https://github.com/ipfs/js-ipfs', dimension: 'Reputation & Trust Models', title: 'IPFS - Distributed Trust System' },
  
  // Audit & Transparency
  { url: 'https://github.com/opentimestamps/opentimestamps-client', dimension: 'Audit & Transparency', title: 'OpenTimestamps - Blockchain Timestamping' },
  { url: 'https://github.com/google/certificate-transparency', dimension: 'Audit & Transparency', title: 'Certificate Transparency Project' },
  { url: 'https://github.com/ethereum/go-ethereum', dimension: 'Audit & Transparency', title: 'Go Ethereum - Blockchain Platform' },
  { url: 'https://github.com/bitcoin/bitcoin', dimension: 'Audit & Transparency', title: 'Bitcoin Core - Blockchain Implementation' },
  
  // Community Sentiment & Adoption
  { url: 'https://news.ycombinator.com/item?id=25000000', dimension: 'Community Sentiment & Adoption', title: 'HN Discussion on Provably Fair Gaming' },
  { url: 'https://www.reddit.com/r/crypto/top/', dimension: 'Community Sentiment & Adoption', title: 'Crypto Reddit - Community Discussions' },
  
  // Risk & Ethical Considerations
  { url: 'https://gdpr.eu/what-is-gdpr/', dimension: 'Risk & Ethical Considerations', title: 'GDPR Overview and Requirements' },
  { url: 'https://www.w3.org/WAI/WCAG21/quickref/', dimension: 'Risk & Ethical Considerations', title: 'WCAG 2.1 Quick Reference' },
  { url: 'https://oag.ca.gov/privacy/ccpa', dimension: 'Risk & Ethical Considerations', title: 'California Consumer Privacy Act (CCPA)' },
  
  // Competitive & Differentiation Analysis
  { url: 'https://github.com/foundry-rs/foundry', dimension: 'Competitive & Differentiation Analysis', title: 'Foundry VTT - Virtual Tabletop Platform' },
  { url: 'https://github.com/DiceDB/dice', dimension: 'Competitive & Differentiation Analysis', title: 'DiceDB - Dice Rolling Service' },
  { url: 'https://github.com/roll20/roll20-api-scripts', dimension: 'Competitive & Differentiation Analysis', title: 'Roll20 API Scripts' },
  { url: 'https://github.com/hedgedoc/hedgedoc', dimension: 'Competitive & Differentiation Analysis', title: 'HedgeDoc - Collaborative Documentation' }
];

/**
 * Sleep utility for rate limiting
 * @param {number} ms - Milliseconds to sleep
 * @returns {Promise<void>}
 */
function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Plan and return a structured list of research collection tasks
 * 
 * @returns {Array<Object>} Array of task objects with metadata
 */
function planTasks() {
  return [
    {
      id: 'task-001',
      dimension: 'Existing Platforms & Benchmarks',
      description: 'Survey crypto casino provably fair implementations',
      priority: 'high',
      estimatedSources: 5,
      keywords: ['provably fair', 'crypto casino', 'dice game', 'RNG verification'],
      targetTypes: ['Product', 'Blog', 'Open-Source']
    },
    {
      id: 'task-002',
      dimension: 'Randomness & Fairness',
      description: 'Research Chainlink VRF and alternatives',
      priority: 'high',
      estimatedSources: 4,
      keywords: ['Chainlink VRF', 'verifiable random function', 'drand', 'randomness beacon'],
      targetTypes: ['Academic', 'Standard', 'Product']
    },
    {
      id: 'task-003',
      dimension: 'Anti-Cheat & Verification',
      description: 'Investigate computer vision for dice recognition',
      priority: 'high',
      estimatedSources: 6,
      keywords: ['computer vision', 'dice recognition', 'pip detection', 'OpenCV', 'object detection'],
      targetTypes: ['Academic', 'Open-Source', 'Blog']
    },
    {
      id: 'task-004',
      dimension: 'Reputation & Trust Models',
      description: 'Analyze ELO, Glicko, and Bayesian trust systems',
      priority: 'medium',
      estimatedSources: 4,
      keywords: ['ELO rating', 'Glicko', 'Bayesian trust', 'reputation system', 'Sybil resistance'],
      targetTypes: ['Academic', 'Blog', 'Product']
    },
    {
      id: 'task-005',
      dimension: 'Audit & Transparency',
      description: 'Research Merkle trees and blockchain anchoring',
      priority: 'medium',
      estimatedSources: 4,
      keywords: ['Merkle tree', 'blockchain anchoring', 'OpenTimestamps', 'audit log', 'certificate transparency'],
      targetTypes: ['Standard', 'Academic', 'Open-Source']
    },
    {
      id: 'task-006',
      dimension: 'Community Sentiment & Adoption',
      description: 'Monitor Reddit, HN discussions on verification systems',
      priority: 'low',
      estimatedSources: 3,
      keywords: ['dice rolling fairness', 'verification overhead', 'trust vs convenience'],
      targetTypes: ['Forum']
    },
    {
      id: 'task-007',
      dimension: 'Risk & Ethical Considerations',
      description: 'Review GDPR, CCPA requirements for video data',
      priority: 'high',
      estimatedSources: 4,
      keywords: ['GDPR video', 'CCPA compliance', 'biometric privacy', 'data retention'],
      targetTypes: ['Standard', 'Blog']
    },
    {
      id: 'task-008',
      dimension: 'Competitive & Differentiation Analysis',
      description: 'Analyze existing dice rolling platforms and features',
      priority: 'medium',
      estimatedSources: 5,
      keywords: ['dice rolling platform', 'tabletop online', 'Roll20', 'competitive gaming'],
      targetTypes: ['Product', 'Forum', 'Blog']
    }
  ];
}

/**
 * Fetch metadata for a given URL
 * 
 * Performs actual HTTP fetching with timeout and error handling.
 * Extracts metadata from HTML including title, description, and content.
 * 
 * @param {string} url - The URL to fetch metadata from
 * @returns {Promise<Object>} Metadata object with title, description, author, date, etc.
 */
async function fetchMetadata(url) {
  return new Promise((resolve, reject) => {
    const urlObj = new URL(url);
    const protocol = urlObj.protocol === 'https:' ? https : http;
    
    const options = {
      hostname: urlObj.hostname,
      path: urlObj.pathname + urlObj.search,
      method: 'GET',
      headers: {
        'User-Agent': 'Mozilla/5.0 (Research Bot) DiceRoll/1.0',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
      },
      timeout: 10000
    };
    
    const req = protocol.request(options, (res) => {
      let data = '';
      
      // Handle redirects
      if (res.statusCode >= 300 && res.statusCode < 400 && res.headers.location) {
        const redirectUrl = new URL(res.headers.location, url);
        return fetchMetadata(redirectUrl.href).then(resolve).catch(reject);
      }
      
      if (res.statusCode !== 200) {
        return resolve({
          url: url,
          title: null,
          description: null,
          author: null,
          publishDate: null,
          lastModified: null,
          contentType: res.headers['content-type'],
          wordCount: null,
          domainAuthority: null,
          error: `HTTP ${res.statusCode}`,
          fetchedAt: new Date().toISOString()
        });
      }
      
      res.on('data', chunk => data += chunk);
      res.on('end', () => {
        try {
          const $ = cheerio.load(data);
          
          // Extract metadata
          const title = $('title').text().trim() || 
                       $('meta[property="og:title"]').attr('content') ||
                       $('meta[name="twitter:title"]').attr('content') ||
                       $('h1').first().text().trim();
          
          const description = $('meta[name="description"]').attr('content') ||
                             $('meta[property="og:description"]').attr('content') ||
                             $('meta[name="twitter:description"]').attr('content') ||
                             $('p').first().text().trim().substring(0, 200);
          
          const author = $('meta[name="author"]').attr('content') ||
                        $('meta[property="article:author"]').attr('content') ||
                        $('[rel="author"]').text().trim();
          
          const publishDate = $('meta[property="article:published_time"]').attr('content') ||
                             $('meta[name="date"]').attr('content') ||
                             $('time[datetime]').attr('datetime');
          
          const lastModified = $('meta[property="article:modified_time"]').attr('content') ||
                              res.headers['last-modified'];
          
          // Calculate word count from main content
          const bodyText = $('article, main, .content, .post, body').first().text();
          const wordCount = bodyText ? bodyText.trim().split(/\s+/).length : 0;
          
          resolve({
            url: url,
            title: title || null,
            description: description || null,
            author: author || null,
            publishDate: publishDate || null,
            lastModified: lastModified || null,
            contentType: res.headers['content-type'],
            wordCount: wordCount > 0 ? wordCount : null,
            domainAuthority: calculateDomainAuthority(urlObj.hostname),
            error: null,
            fetchedAt: new Date().toISOString()
          });
        } catch (error) {
          resolve({
            url: url,
            title: null,
            description: null,
            author: null,
            publishDate: null,
            lastModified: null,
            contentType: res.headers['content-type'],
            wordCount: null,
            domainAuthority: null,
            error: error.message,
            fetchedAt: new Date().toISOString()
          });
        }
      });
    });
    
    req.on('error', (error) => {
      resolve({
        url: url,
        title: null,
        description: null,
        author: null,
        publishDate: null,
        lastModified: null,
        contentType: null,
        wordCount: null,
        domainAuthority: null,
        error: error.message,
        fetchedAt: new Date().toISOString()
      });
    });
    
    req.on('timeout', () => {
      req.destroy();
      resolve({
        url: url,
        title: null,
        description: null,
        author: null,
        publishDate: null,
        lastModified: null,
        contentType: null,
        wordCount: null,
        domainAuthority: null,
        error: 'Request timeout',
        fetchedAt: new Date().toISOString()
      });
    });
    
    req.end();
  });
}

/**
 * Calculate domain authority based on hostname
 * Simplified heuristic based on known high-authority domains
 * 
 * @param {string} hostname - Domain hostname
 * @returns {number} Authority score 1-5
 */
function calculateDomainAuthority(hostname) {
  const highAuthority = ['github.com', 'arxiv.org', 'ieee.org', 'acm.org', 'nist.gov', 
                         'w3.org', 'ietf.org', 'ethereum.org', 'bitcoin.org'];
  const mediumAuthority = ['stackoverflow.com', 'reddit.com', 'medium.com', 
                          'docs.microsoft.com', 'developer.mozilla.org'];
  
  if (highAuthority.some(domain => hostname.includes(domain))) return 5;
  if (mediumAuthority.some(domain => hostname.includes(domain))) return 4;
  if (hostname.endsWith('.edu') || hostname.endsWith('.gov')) return 4;
  if (hostname.endsWith('.org')) return 3;
  return 2;
}

/**
 * Classify a source based on its metadata
 * 
 * Uses heuristics to determine source type from URL patterns, 
 * content structure, and metadata. Uses proper URL parsing to
 * extract hostname for security.
 * 
 * TODO: Implement ML-based classification for ambiguous cases
 * TODO: Add confidence scores to classifications
 * 
 * @param {Object} metadata - Source metadata from fetchMetadata()
 * @returns {string} Source type: Academic, Open-Source, Standard, Forum, Product, Blog
 */
function classifySource(metadata) {
  if (!metadata || !metadata.url) {
    return 'Unknown';
  }
  
  let hostname;
  let pathname;
  
  try {
    // Parse URL properly to extract hostname (prevents URL bypassing)
    const urlObj = new URL(metadata.url);
    hostname = urlObj.hostname.toLowerCase();
    pathname = urlObj.pathname.toLowerCase();
  } catch (error) {
    // Invalid URL
    return 'Unknown';
  }
  
  // Academic sources - check exact hostname matches
  if (hostname === 'arxiv.org' || 
      hostname.endsWith('.arxiv.org') ||
      hostname === 'ieeexplore.ieee.org' ||
      hostname.endsWith('.ieee.org') ||
      hostname === 'dl.acm.org' ||
      hostname.endsWith('.acm.org') ||
      hostname.endsWith('.edu') ||
      hostname === 'scholar.google.com') {
    return 'Academic';
  }
  
  // Open-Source repositories - check exact hostname matches
  if (hostname === 'github.com' || 
      hostname.endsWith('.github.com') ||
      hostname === 'gitlab.com' ||
      hostname.endsWith('.gitlab.com') ||
      hostname === 'bitbucket.org' ||
      hostname.endsWith('.bitbucket.org')) {
    return 'Open-Source';
  }
  
  // Standards and specifications - check exact hostname matches
  if (hostname === 'ietf.org' || 
      hostname.endsWith('.ietf.org') ||
      hostname === 'w3.org' ||
      hostname.endsWith('.w3.org') ||
      hostname === 'rfc-editor.org' ||
      hostname.endsWith('.rfc-editor.org') ||
      hostname === 'nist.gov' ||
      hostname.endsWith('.nist.gov')) {
    return 'Standard';
  }
  
  // Forum discussions - check exact hostname matches
  if (hostname === 'reddit.com' || 
      hostname.endsWith('.reddit.com') ||
      hostname === 'news.ycombinator.com' ||
      hostname === 'stackoverflow.com' ||
      hostname.endsWith('.stackoverflow.com') ||
      hostname === 'discord.com' ||
      hostname.endsWith('.discord.com')) {
    return 'Forum';
  }
  
  // Product documentation - check path patterns
  if (pathname.includes('/docs/') || 
      pathname.includes('/documentation/') ||
      pathname.includes('whitepaper')) {
    return 'Product';
  }
  
  // Default to Blog for other content
  // TODO: Improve classification with content analysis
  return 'Blog';
}

/**
 * Score a source based on quality criteria
 * 
 * Evaluates recency, authority, relevance, technical depth, and bias indicators.
 * 
 * @param {Object} metadata - Source metadata from fetchMetadata()
 * @param {string} dimension - Research dimension for relevance scoring
 * @returns {Object} Score object with individual dimension scores and overall score
 */
function scoreSource(metadata, dimension = null) {
  const scores = {
    recency: calculateRecencyScore(metadata.publishDate),
    authority: calculateAuthorityScore(metadata),
    relevance: dimension ? calculateRelevanceScore(metadata, dimension) : null,
    depth: calculateDepthScore(metadata),
    bias: assessBias(metadata),
    overall: null
  };
  
  // Calculate weighted average for overall score
  // Weights: recency(10%), authority(20%), relevance(25%), depth(25%), bias(20%)
  const weights = {
    recency: 0.10,
    authority: 0.20,
    relevance: 0.25,
    depth: 0.25,
    bias: 0.20
  };
  
  // Convert bias to numeric score
  const biasScore = scores.bias === 'Clear' ? 5 : scores.bias === 'Moderate' ? 3 : scores.bias === 'High' ? 1 : 3;
  
  // Only calculate if we have at least authority and depth
  if (scores.authority !== null && scores.depth !== null) {
    let totalWeight = 0;
    let weightedSum = 0;
    
    if (scores.recency !== null) {
      totalWeight += weights.recency;
      weightedSum += scores.recency * weights.recency;
    }
    
    if (scores.authority !== null) {
      totalWeight += weights.authority;
      weightedSum += scores.authority * weights.authority;
    }
    
    if (scores.relevance !== null) {
      totalWeight += weights.relevance;
      weightedSum += scores.relevance * weights.relevance;
    }
    
    if (scores.depth !== null) {
      totalWeight += weights.depth;
      weightedSum += scores.depth * weights.depth;
    }
    
    totalWeight += weights.bias;
    weightedSum += biasScore * weights.bias;
    
    if (totalWeight > 0) {
      scores.overall = (weightedSum / totalWeight).toFixed(2);
    }
  }
  
  return scores;
}

/**
 * Calculate recency score based on publication date
 * 
 * @param {string|Date} publishDate - Publication date
 * @returns {number|null} Score from 1-5, or null if date unavailable
 */
function calculateRecencyScore(publishDate) {
  if (!publishDate) return null;
  
  try {
    const pubDate = new Date(publishDate);
    const now = new Date();
    const ageYears = (now - pubDate) / (365.25 * 24 * 60 * 60 * 1000);
    
    if (ageYears < 1) return 5;
    if (ageYears < 2) return 4;
    if (ageYears < 3) return 3;
    if (ageYears < 5) return 2;
    return 1;
  } catch (error) {
    return null;
  }
}

/**
 * Calculate authority score based on source metadata
 * 
 * @param {Object} metadata - Source metadata
 * @returns {number|null} Score from 1-5, or null if unable to determine
 */
function calculateAuthorityScore(metadata) {
  if (!metadata || !metadata.url) return null;
  
  // Use domain authority if available
  if (metadata.domainAuthority) {
    return metadata.domainAuthority;
  }
  
  // Fallback to URL-based heuristics
  try {
    const urlObj = new URL(metadata.url);
    return calculateDomainAuthority(urlObj.hostname);
  } catch (error) {
    return null;
  }
}

/**
 * Calculate relevance score for a specific research dimension
 * 
 * @param {Object} metadata - Source metadata
 * @param {string} dimension - Research dimension name
 * @returns {number|null} Score from 1-5, or null if unable to determine
 */
function calculateRelevanceScore(metadata, dimension) {
  if (!metadata || !dimension) return null;
  
  // Keywords for each dimension
  const dimensionKeywords = {
    'Existing Platforms & Benchmarks': ['provably fair', 'dice', 'casino', 'gaming', 'rng verification', 'roll20', 'tabletop'],
    'Randomness & Fairness': ['vrf', 'random', 'verifiable', 'chainlink', 'drand', 'beacon', 'cryptographic'],
    'Anti-Cheat & Verification': ['computer vision', 'opencv', 'detection', 'recognition', 'deepfake', 'authentication'],
    'Reputation & Trust Models': ['elo', 'glicko', 'reputation', 'trust', 'scoring', 'ranking', 'sybil'],
    'Audit & Transparency': ['blockchain', 'merkle', 'timestamp', 'audit', 'certificate transparency', 'immutable'],
    'Community Sentiment & Adoption': ['community', 'discussion', 'adoption', 'sentiment', 'feedback'],
    'Risk & Ethical Considerations': ['privacy', 'gdpr', 'ccpa', 'accessibility', 'wcag', 'regulatory'],
    'Competitive & Differentiation Analysis': ['foundry', 'platform', 'competitor', 'alternative', 'comparison']
  };
  
  const keywords = dimensionKeywords[dimension] || [];
  const title = (metadata.title || '').toLowerCase();
  const description = (metadata.description || '').toLowerCase();
  const url = (metadata.url || '').toLowerCase();
  
  const combinedText = `${title} ${description} ${url}`;
  
  // Count keyword matches
  const matches = keywords.filter(keyword => combinedText.includes(keyword)).length;
  const matchRatio = matches / Math.max(keywords.length, 1);
  
  if (matchRatio >= 0.4) return 5;
  if (matchRatio >= 0.3) return 4;
  if (matchRatio >= 0.2) return 3;
  if (matchRatio >= 0.1) return 2;
  if (matches > 0) return 1;
  
  return null;
}

/**
 * Calculate technical depth score
 * 
 * @param {Object} metadata - Source metadata
 * @returns {number|null} Score from 1-5, or null if unable to determine
 */
function calculateDepthScore(metadata) {
  if (!metadata) return null;
  
  // GitHub repositories get high depth score
  if (metadata.url && metadata.url.includes('github.com')) {
    return 4;
  }
  
  // Academic and standard sources get high depth
  const type = classifySource(metadata);
  if (type === 'Academic' || type === 'Standard') {
    return 5;
  }
  
  // Use word count as a proxy
  if (metadata.wordCount) {
    if (metadata.wordCount > 3000) return 5;
    if (metadata.wordCount > 2000) return 4;
    if (metadata.wordCount > 1000) return 3;
    if (metadata.wordCount > 500) return 2;
    return 1;
  }
  
  return 3; // Default moderate depth
}

/**
 * Assess potential bias in source
 * 
 * @param {Object} metadata - Source metadata
 * @returns {string} 'Clear', 'Moderate', or 'High' bias assessment
 */
function assessBias(metadata) {
  if (!metadata || !metadata.url) return 'Unknown';
  
  const url = metadata.url.toLowerCase();
  
  // Academic, standards, and open-source generally have clear bias disclosure
  if (url.includes('arxiv.org') || 
      url.includes('github.com') ||
      url.includes('ietf.org') ||
      url.includes('w3.org') ||
      url.includes('nist.gov') ||
      url.includes('.edu')) {
    return 'Clear';
  }
  
  // Commercial domains may have moderate bias
  if (url.includes('.com') && !url.includes('github.com')) {
    return 'Moderate';
  }
  
  return 'Clear'; // Default assumption
}

/**
 * Main execution function - Phase 2 Implementation
 * Collects real sources, scores them, and updates RESEARCH_SOURCES.md
 */
async function main() {
  console.log('='.repeat(70));
  console.log('Research Source Collection Script - Phase 2 Live Collection');
  console.log('='.repeat(70));
  console.log();
  
  console.log('üîç Starting live source collection...');
  console.log(`Target: ${SOURCES_TO_COLLECT.length} sources across 8 dimensions`);
  console.log();
  
  const collectedSources = [];
  let successCount = 0;
  let errorCount = 0;
  
  for (let i = 0; i < SOURCES_TO_COLLECT.length; i++) {
    const source = SOURCES_TO_COLLECT[i];
    console.log(`[${i + 1}/${SOURCES_TO_COLLECT.length}] Fetching: ${source.url}`);
    
    try {
      const metadata = await fetchMetadata(source.url);
      
      if (metadata.error) {
        console.log(`  ‚ö†Ô∏è  Error: ${metadata.error}`);
        errorCount++;
      } else {
        console.log(`  ‚úì Success: ${metadata.title || 'Untitled'}`);
        successCount++;
      }
      
      // Classify and score the source
      const sourceType = classifySource(metadata);
      const scores = scoreSource(metadata, source.dimension);
      
      collectedSources.push({
        id: `SRC-${String(i + 1).padStart(3, '0')}`,
        url: source.url,
        dimension: source.dimension,
        title: metadata.title || source.title,
        type: sourceType,
        metadata: metadata,
        scores: scores,
        collectedAt: new Date().toISOString()
      });
      
      // Rate limiting - wait between requests
      await sleep(1000);
      
    } catch (error) {
      console.log(`  ‚ùå Exception: ${error.message}`);
      errorCount++;
      
      collectedSources.push({
        id: `SRC-${String(i + 1).padStart(3, '0')}`,
        url: source.url,
        dimension: source.dimension,
        title: source.title,
        type: 'Unknown',
        metadata: { url: source.url, error: error.message },
        scores: { overall: null },
        collectedAt: new Date().toISOString()
      });
    }
  }
  
  console.log();
  console.log('='.repeat(70));
  console.log('üìä Collection Summary:');
  console.log('='.repeat(70));
  console.log(`Total Sources: ${collectedSources.length}`);
  console.log(`Successful: ${successCount}`);
  console.log(`Errors: ${errorCount}`);
  console.log();
  
  // Calculate statistics
  const validScores = collectedSources
    .filter(s => s.scores.overall !== null)
    .map(s => parseFloat(s.scores.overall));
  
  const avgScore = validScores.length > 0
    ? (validScores.reduce((a, b) => a + b, 0) / validScores.length).toFixed(2)
    : 'N/A';
  
  console.log(`Average Quality Score: ${avgScore}`);
  console.log();
  
  // Update RESEARCH_SOURCES.md
  console.log('üìù Updating RESEARCH_SOURCES.md...');
  await updateResearchSourcesDocument(collectedSources);
  console.log('‚úÖ RESEARCH_SOURCES.md updated successfully!');
  console.log();
  
  console.log('='.repeat(70));
  console.log('Phase 2 collection complete!');
  console.log('='.repeat(70));
}

/**
 * Update RESEARCH_SOURCES.md with collected sources
 * @param {Array} sources - Collected source objects
 */
async function updateResearchSourcesDocument(sources) {
  const researchSourcesPath = path.join(__dirname, '../../RESEARCH_SOURCES.md');
  
  // Group sources by dimension
  const sourcesByDimension = {};
  sources.forEach(source => {
    if (!sourcesByDimension[source.dimension]) {
      sourcesByDimension[source.dimension] = [];
    }
    sourcesByDimension[source.dimension].push(source);
  });
  
  // Build the document content
  let content = `# Research Sources Catalog

## Overview
This document serves as a living catalog of curated sources for the competitive remote dice roll gaming platform research. Sources are classified by type, scored for quality, and organized by research dimension.

**Status:** Phase 2 Complete - Live Sources Collected  
**Last Updated:** ${new Date().toISOString().split('T')[0]}  
**Total Sources:** ${sources.length}  
**Average Quality Score:** ${calculateAverageScore(sources)}

## Source Classification Taxonomy

### Source Types
- **Academic**: Peer-reviewed papers, conference proceedings, theses
- **Open-Source**: GitHub/GitLab repositories, code libraries
- **Standard**: RFCs, W3C specs, industry standards
- **Forum**: Reddit, HN, Discord, StackOverflow discussions
- **Product**: Commercial documentation, whitepapers, case studies
- **Blog**: Technical blogs, opinion pieces, industry commentary

### Quality Scoring Dimensions
Each source is scored on a 1-5 scale across multiple dimensions:
- **Recency**: How recent is the information?
- **Authority**: Reputation and credibility of source
- **Relevance**: Direct applicability to platform requirements
- **Depth**: Technical detail and implementation guidance
- **Bias**: Transparency about conflicts of interest

**Overall Score Calculation:** Weighted average across dimensions

## Sources by Research Dimension

`;

  // Add sources for each dimension
  const dimensions = [
    'Existing Platforms & Benchmarks',
    'Randomness & Fairness',
    'Anti-Cheat & Verification',
    'Reputation & Trust Models',
    'Audit & Transparency',
    'Community Sentiment & Adoption',
    'Risk & Ethical Considerations',
    'Competitive & Differentiation Analysis'
  ];
  
  dimensions.forEach((dimension, index) => {
    content += `### ${index + 1}. ${dimension}\n`;
    content += `**Focus:** ${getDimensionFocus(dimension)}\n\n`;
    
    const dimSources = sourcesByDimension[dimension] || [];
    
    if (dimSources.length > 0) {
      dimSources.forEach(source => {
        content += formatSource(source);
      });
    } else {
      content += `*No sources collected for this dimension yet.*\n\n`;
    }
    
    content += `---\n\n`;
  });
  
  // Add statistics section
  content += `## Statistics

### Current Status
- Total Sources: ${sources.length}
- By Type: ${getTypeBreakdown(sources)}
- Average Quality Score: ${calculateAverageScore(sources)}
- Coverage by Dimension: ${getCoverageSummary(sourcesByDimension, dimensions)}

### Collection Metadata
- Collection Date: ${new Date().toISOString().split('T')[0]}
- Collection Method: Automated web scraping with manual curation
- Rate Limiting: 1 second between requests
- Success Rate: ${calculateSuccessRate(sources)}%

---

**Document Status:** Active - Phase 2 Complete  
**Next Milestone:** Phase 3 - Comparative Analysis  
**Owner:** Research Team
`;

  fs.writeFileSync(researchSourcesPath, content, 'utf8');
}

/**
 * Format a source for markdown output
 */
function formatSource(source) {
  const score = source.scores.overall || 'N/A';
  const bias = source.scores.bias || 'Unknown';
  
  let output = `#### [${source.id}] ${source.title}\n`;
  output += `**Type:** ${source.type}  \n`;
  output += `**URL:** ${source.url}  \n`;
  output += `**Collected:** ${source.collectedAt.split('T')[0]}\n\n`;
  
  output += `**Scores:**\n`;
  output += `- Recency: ${source.scores.recency || 'N/A'}\n`;
  output += `- Authority: ${source.scores.authority || 'N/A'}\n`;
  output += `- Relevance: ${source.scores.relevance || 'N/A'}\n`;
  output += `- Depth: ${source.scores.depth || 'N/A'}\n`;
  output += `- Bias: ${bias}\n`;
  output += `- **Overall:** ${score}\n\n`;
  
  if (source.metadata.description) {
    output += `**Summary:**\n`;
    output += `${source.metadata.description.substring(0, 250)}${source.metadata.description.length > 250 ? '...' : ''}\n\n`;
  }
  
  if (source.metadata.error) {
    output += `**Note:** Collection error - ${source.metadata.error}\n\n`;
  }
  
  output += `\n`;
  return output;
}

/**
 * Get dimension focus description
 */
function getDimensionFocus(dimension) {
  const focuses = {
    'Existing Platforms & Benchmarks': 'Remote dice/tabletop game integrity, online RNG fairness frameworks',
    'Randomness & Fairness': 'Cryptographic RNG techniques, VRF, randomness beacons',
    'Anti-Cheat & Verification': 'Video authentication, computer vision dice recognition, fraud detection',
    'Reputation & Trust Models': 'Scoring systems, moderation workflows, Sybil resistance',
    'Audit & Transparency': 'Hash chains, Merkle trees, blockchain anchoring',
    'Community Sentiment & Adoption': 'User discussions, adoption barriers, community feedback',
    'Risk & Ethical Considerations': 'Privacy, regulatory compliance, accessibility',
    'Competitive & Differentiation Analysis': 'Value gaps, market positioning, alternative platforms'
  };
  return focuses[dimension] || '';
}

/**
 * Calculate average quality score
 */
function calculateAverageScore(sources) {
  const validScores = sources
    .filter(s => s.scores.overall !== null && s.scores.overall !== undefined)
    .map(s => parseFloat(s.scores.overall));
  
  if (validScores.length === 0) return 'N/A';
  
  const avg = validScores.reduce((a, b) => a + b, 0) / validScores.length;
  return avg.toFixed(2);
}

/**
 * Get type breakdown
 */
function getTypeBreakdown(sources) {
  const types = {};
  sources.forEach(s => {
    types[s.type] = (types[s.type] || 0) + 1;
  });
  
  return Object.entries(types)
    .map(([type, count]) => `${type} (${count})`)
    .join(', ');
}

/**
 * Get coverage summary
 */
function getCoverageSummary(sourcesByDimension, dimensions) {
  const covered = dimensions.filter(d => 
    sourcesByDimension[d] && sourcesByDimension[d].length > 0
  ).length;
  return `${covered}/${dimensions.length} dimensions`;
}

/**
 * Calculate success rate
 */
function calculateSuccessRate(sources) {
  const successful = sources.filter(s => !s.metadata.error).length;
  return ((successful / sources.length) * 100).toFixed(1);
}

// Execute if run directly
if (require.main === module) {
  main().catch(error => {
    console.error('Fatal error:', error);
    process.exit(1);
  });
}

// Export functions for potential use as a module
module.exports = {
  planTasks,
  fetchMetadata,
  classifySource,
  scoreSource,
  calculateRecencyScore,
  calculateAuthorityScore,
  calculateRelevanceScore,
  calculateDepthScore,
  assessBias,
  main
};
